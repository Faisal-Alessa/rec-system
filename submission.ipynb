{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic, Dataset, Reader, model_selection, SVD, KNNBasic\n",
    "from collections import defaultdict\n",
    "import heapq\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateparse (time_in_secs):    \n",
    "    return datetime.fromtimestamp(float(time_in_secs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "\n",
    "    for uid, iid, _, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():        \n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data  and return train and test sets.\n",
    "def load_dataset(df):\n",
    "    reader = Reader(line_format='user item rating', rating_scale=(1, 5), sep=',', skip_lines=0)\n",
    "    ratings_dataset = Dataset.load_from_df(df, reader)\n",
    "    # Split the dataset into training and test sets\n",
    "    return model_selection.train_test_split(ratings_dataset, test_size=0.20, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = {}\n",
    "\n",
    "    recalls = {}\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('ai case study.csv',\n",
    "               names=['user_id','product_id','rating','timestamp'],\n",
    "               dtype={'user_id':'category','product_id':'category', 'rating':'int'},\n",
    "               parse_dates=['timestamp'],\n",
    "               date_parser=dateparse\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number os users: 4201696\n",
      "Number of items: 476002\n",
      "Rating Scale: 1 - 5\n",
      "Date range: 1998-12-04 03:00:00 - 2014-07-23 03:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f'Number os users: {len(df.user_id.unique())}')\n",
    "print(f'Number of items: {len(df.product_id.unique())}')\n",
    "print(f'Rating Scale: {int(df.rating.min())} - {int(df.rating.max())}')\n",
    "print(f'Date range: {df.timestamp.min()} - {df.timestamp.max()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency of each rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.rating.hist(bins=range(1,7), align='left', rwidth=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the dataframe by date so that when we split the data we test on the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='timestamp', inplace = False).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different recommendation techniques, user-based collaborative filltering and item-based collaborative filltering. We split the data into train and test set using the load_dataset function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_i, testset_i = load_dataset(df[['product_id', 'user_id', 'rating']]) # item based\n",
    "trainset_u, testset_u = load_dataset(df[['user_id', 'product_id', 'rating']]) # user based"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define SVD, a matrix factorizing algorithm and fit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x16b3dd570>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_i = SVD() # item based\n",
    "algo_u = SVD() # user based\n",
    "algo_i.fit(trainset_i)\n",
    "algo_u.fit(trainset_u)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our laerned algorithm on the testset we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_i = algo_i.test(testset_i) # item based\n",
    "results_u = algo_u.test(testset_u) # user based"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swap two columns of the user and item to be able to measure the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (switching item with user to measure the results)\n",
    "results_ip = [[w, v, x, y, z] for v, w, x, y, z in results_i] # processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use precision_recall_at_k function to calculate the precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_i, recalls_i = precision_recall_at_k(results_ip, 5) # top 5\n",
    "precisions_u, recalls_u = precision_recall_at_k(results_u, 5) # top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_precision_i: 0.7027318635233006\n",
      "avg_recall_i: 0.7197603490381925\n",
      "avg_precision_u: 0.7028176631567111\n",
      "avg_recall_u: 0.7199162962884823\n"
     ]
    }
   ],
   "source": [
    "print(f'avg_precision_i: {np.mean(list(precisions_i.values()))}')\n",
    "print(f'avg_recall_i: {np.mean(list(recalls_i.values()))}')\n",
    "print(f'avg_precision_u: {np.mean(list(precisions_u.values()))}')\n",
    "print(f'avg_recall_u: {np.mean(list(recalls_u.values()))}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results for one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[-int(len(df)*0.2):] # taking last 20% of the data\n",
    "predictions = [algo_u.predict('A1WVMDRJU19AFD', item_id) for item_id in test.product_id.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(predictions, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('B00622AG6S', 5),\n",
       "  ('B004HFJGYU', 5),\n",
       "  ('B009W8EWOG', 5),\n",
       "  ('B00913NPYK', 5),\n",
       "  ('B00DVFLJDS', 5)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(top_n.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try different approach, we will use a similarity algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = load_dataset(df[['user_id', 'product_id', 'rating']][:30000]) # Can't use all data due to lack of memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will try both item and user based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix_i = KNNBasic(sim_options={\n",
    "        'name': 'cosine',\n",
    "        'user_based': False\n",
    "        })\\\n",
    "        .fit(trainset)\n",
    "similarity_matrix_u = KNNBasic(sim_options={\n",
    "        'name': 'cosine',\n",
    "        'user_based': True\n",
    "        })\\\n",
    "        .fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_i = similarity_matrix_i.test(testset)\n",
    "results_u = similarity_matrix_u.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_i, recalls_i = precision_recall_at_k(results_i, 6000, threshold=3.5)\n",
    "precisions_u, recalls_u = precision_recall_at_k(results_u, 6000, threshold=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_precision_i: 0.6951013630628007\n",
      "avg_recall_i: 0.7081242980157245\n",
      "avg_precision_u: 0.6948213617157833\n",
      "avg_recall_u: 0.7077172889509094\n"
     ]
    }
   ],
   "source": [
    "print(f'avg_precision_i: {np.mean(list(precisions_i.values()))}')\n",
    "print(f'avg_recall_i: {np.mean(list(recalls_i.values()))}')\n",
    "print(f'avg_precision_u: {np.mean(list(precisions_u.values()))}')\n",
    "print(f'avg_recall_u: {np.mean(list(recalls_u.values()))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing on one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example one case\n",
    "test_subject_iid = trainset.to_inner_uid('A1WVMDRJU19AFD')\n",
    "\n",
    "# Get the top K items we rated\n",
    "test_subject_ratings = trainset.ur[test_subject_iid]\n",
    "k_neighbors = heapq.nlargest(5, test_subject_ratings, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = similarity_matrix_i.compute_similarities()\n",
    "candidates = defaultdict(float)\n",
    "\n",
    "for itemID, rating in k_neighbors:\n",
    "    try:\n",
    "      similaritities = similarity_matrix[itemID]\n",
    "      for innerID, score in enumerate(similaritities):\n",
    "          candidates[innerID] += score * (rating / 5.0)\n",
    "    except:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product 1: B00002SWHH\n",
      "Product 2: B00004SC3Y\n",
      "Product 3: B000031KIM\n",
      "Product 4: B00000J3Q7\n",
      "Product 5: B00001QEMF\n"
     ]
    }
   ],
   "source": [
    "rated = {}\n",
    "for itemID, _ in trainset.ur[test_subject_iid]:\n",
    "  rated[itemID] = 1\n",
    "\n",
    "# Add items to list of user's recommendations\n",
    "# If they are similar to their favorite items,\n",
    "# AND have not already been rated it.\n",
    "recommendations = []\n",
    "\n",
    "position = 1\n",
    "for itemID, rating_sum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "  if not itemID in rated:\n",
    "    recommendations.append(trainset.to_raw_iid(itemID))\n",
    "    position += 1\n",
    "    if (position > 5): break # We only want top 5\n",
    "\n",
    "for idx, rec in enumerate(recommendations, 1):\n",
    "  print(f\"Product {idx}:\", rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arabic-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
